{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Boosting Wav2Vec2 with n-grams in ðŸ¤— Transformers",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beinghorizontal/wav2vec2/blob/main/create_n_grams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-mE9CiYHXX4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **part 1. Build an *n-gram* with KenLM** and upload binary to drive\n",
        "\n"
      ],
      "metadata": {
        "id": "OHQXHWZIFN6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, let's see step-by-step how to build an *n-gram*. We will use the popular [KenLM library](https://github.com/kpu/kenlm) to do so. Let's start by installing the Ubuntu library prerequisites:"
      ],
      "metadata": {
        "id": "B4pX7mEXOH_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install build-essential cmake libboost-system-dev libboost-thread-dev libboost-program-options-dev libboost-test-dev libeigen3-dev zlib1g-dev libbz2-dev liblzma-dev"
      ],
      "metadata": {
        "id": "FKMMWfVQp_gP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "before downloading and unpacking the KenLM repo."
      ],
      "metadata": {
        "id": "JzHiJPg6OqvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O - https://kheafield.com/code/kenlm.tar.gz | tar xz"
      ],
      "metadata": {
        "id": "J8mm4ExzqIaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KenLM is written in C++, so we'll make use of `cmake` to build the binaries."
      ],
      "metadata": {
        "id": "TKpjSxiDPKK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir kenlm/build && cd kenlm/build && cmake .. && make -j2\n",
        "!ls kenlm/build/bin"
      ],
      "metadata": {
        "id": "MS4mqMyZqVAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, as we can see, the executable functions have successfully been built under `kenlm/build/bin/`.\n",
        "\n",
        "KenLM by default computes an *n-gram* with [Kneser-Ney smooting](https://en.wikipedia.org/wiki/Kneser%E2%80%93Ney_smoothing). All text data used to create the *n-gram* is expected to be stored in a text file.\n",
        "We download our dataset and save it as a `.txt` file."
      ],
      "metadata": {
        "id": "N9D7JvVuPTOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try without flag first\n",
        "!kenlm/build/bin/lmplz -o 5 <\"/content/drive/MyDrive/textfile_ngram.txt\" > \"5gram.arpa\"\n",
        "\n",
        "#!kenlm/build/bin/lmplz -o 5 <\"/content/drive/MyDrive/textfile_ngram.txt\" > \"5gram.arpa\" --discount_fallback\n"
      ],
      "metadata": {
        "id": "_MdDNBlZrPOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, we have built a *5-gram* LM! Let's inspect the first couple of lines."
      ],
      "metadata": {
        "id": "1_58ktqcTBYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head -20 5gram.arpa"
      ],
      "metadata": {
        "id": "TRnV8Miusl--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a small problem that ðŸ¤— Transformers will not be happy about later on.\n",
        "The *5-gram* correctly includes a \"Unknown\" or `<unk>`, as well as a *begin-of-sentence*, `<s>` token, but no *end-of-sentence*, `</s>` token.\n",
        "This sadly has to be corrected currently after the build.\n",
        "\n",
        "We can simply add the *end-of-sentence* token by adding the line `0 </s>  -0.11831701` below the *begin-of-sentence* token and increasing the `ngram 1` count by 1. Because the file has roughly 100 million lines, this command will take *ca.* 2 minutes."
      ],
      "metadata": {
        "id": "l3jfwr2RTKPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"5gram.arpa\", \"r\") as read_file, open(\"5gram_correct.arpa\", \"w\") as write_file:\n",
        "  has_added_eos = False\n",
        "  for line in read_file:\n",
        "    if not has_added_eos and \"ngram 1=\" in line:\n",
        "      count=line.strip().split(\"=\")[-1]\n",
        "      write_file.write(line.replace(f\"{count}\", f\"{int(count)+1}\"))\n",
        "    elif not has_added_eos and \"<s>\" in line:\n",
        "      write_file.write(line)\n",
        "      write_file.write(line.replace(\"<s>\", \"</s>\"))\n",
        "      has_added_eos = True\n",
        "    else:\n",
        "      write_file.write(line)"
      ],
      "metadata": {
        "id": "_7u7dVPkvyRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now inspect the corrected *5-gram*."
      ],
      "metadata": {
        "id": "u9Y8uC3VW5vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head -20 5gram_correct.arpa"
      ],
      "metadata": {
        "id": "YF1RSm-Pxst5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, this looks better! We're done at this point and all that is left to do is to correctly integrate the `\"ngram\"` with [`pyctcdecode`](https://github.com/kensho-technologies/pyctcdecode) and ðŸ¤— Transformers."
      ],
      "metadata": {
        "id": "m7NfKtyjXCiE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### compress to binary"
      ],
      "metadata": {
        "id": "Qhwcy9aCczQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kenlm/build/bin/build_binary /content/5gram_correct.arpa /content/5gram.bin"
      ],
      "metadata": {
        "id": "RR_yll5ec3Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Combine an *n-gram* with Wav2Vec2**"
      ],
      "metadata": {
        "id": "6maVIrRn2Q4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.18.0\n"
      ],
      "metadata": {
        "id": "yTPnzom-26mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
        "\n",
        "# processor = Wav2Vec2Processor.from_pretrained(\"crossdelenna/wav2vec2-base-en-in\")\n",
        "# model = Wav2Vec2ForCTC.from_pretrained(\"crossdelenna/wav2vec2-base-en-in\")"
      ],
      "metadata": {
        "id": "e_4SNFSz38C-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\"crossdelenna/wav2vec2-base-en-in\")"
      ],
      "metadata": {
        "id": "lis0o0_y2Pih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_dict = processor.tokenizer.get_vocab()\n",
        "sorted_vocab_dict = {k.lower(): v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}"
      ],
      "metadata": {
        "id": "v6VGMCRU4gyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install https://github.com/kpu/kenlm/archive/master.zip\n",
        "!pip install pyctcdecode==0.3.0\n"
      ],
      "metadata": {
        "id": "ImTOKeqB46hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyctcdecode import build_ctcdecoder\n",
        "\n",
        "decoder = build_ctcdecoder(\n",
        "    labels=list(sorted_vocab_dict.keys()),\n",
        "    kenlm_model_path=\"/content/drive/MyDrive/5gram_correct.arpa\",\n",
        ")"
      ],
      "metadata": {
        "id": "Jfg4UL5j4jwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can safely ignore the warning and all that is left to do now is to wrap the just created `decoder`, together with the processor's `tokenizer` and `feature_extractor` into a `Wav2Vec2ProcessorWithLM` class."
      ],
      "metadata": {
        "id": "6XllNCOu5xez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Wav2Vec2ProcessorWithLM\n",
        "\n",
        "processor_with_lm = Wav2Vec2ProcessorWithLM(\n",
        "    feature_extractor=processor.feature_extractor,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    decoder=decoder\n",
        ")"
      ],
      "metadata": {
        "id": "RgPEOiZY5zTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before uploading LM evaluate with and without LM"
      ],
      "metadata": {
        "id": "bXB--lzq-NwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets==2.0.0\n",
        "import datasets\n",
        "timit = datasets.load_dataset(\"crossdelenna/en_in\", use_auth_token='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')\n"
      ],
      "metadata": {
        "id": "Hylb6-7U-P3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timit"
      ],
      "metadata": {
        "id": "5kOt9vio-NQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# check random audio"
      ],
      "metadata": {
        "id": "D_T6g_P_Gtcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd\n",
        "audio_sample = timit['test'][3]['input_values']\n",
        "#print(audio_sample[\"labels\"].lower())\n",
        "ipd.Audio(data=audio_sample, autoplay=True, rate=16000)"
      ],
      "metadata": {
        "id": "ZDtV4lCJ_KMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCTC, Wav2Vec2Processor\n",
        "\n",
        "model = AutoModelForCTC.from_pretrained(\"crossdelenna/wav2vec2-base-en-in\")\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"crossdelenna/wav2vec2-base-en-in\")\n",
        "#processor = Wav2Vec2Processor.from_pretrained(\"crossdelenna/wav2vec2-base-en-in\")"
      ],
      "metadata": {
        "id": "lyuIZzN3G0uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Wav2Vec2ForCTC\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"crossdelenna/wav2vec2-base-en-in\").cuda()"
      ],
      "metadata": {
        "id": "9EVYb6F-HT-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = Wav2Vec2Processor.from_pretrained(\"crossdelenna/wav2vec2-base-en-in\")"
      ],
      "metadata": {
        "id": "5zeCBKszNWIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "def map_to_result(batch):\n",
        "  with torch.no_grad():\n",
        "    input_values = torch.tensor(batch[\"input_values\"], device=\"cuda\").unsqueeze(0)\n",
        "    logits = model(input_values).logits\n",
        "\n",
        "  pred_ids = torch.argmax(logits, dim=-1)\n",
        "  batch[\"pred_str\"] = processor.batch_decode(pred_ids)[0]\n",
        "  batch[\"text\"] = processor.decode(batch[\"labels\"], group_tokens=False)\n",
        "  \n",
        "  return batch"
      ],
      "metadata": {
        "id": "AWlsnOESN2Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = timit[\"test\"].map(map_to_result, remove_columns=timit[\"test\"].column_names)"
      ],
      "metadata": {
        "id": "ohszh94MN_6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer\n",
        "from datasets import load_metric\n",
        "\n",
        "wer_metric = load_metric(\"wer\")"
      ],
      "metadata": {
        "id": "9zS9oheeOjqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test WER: {:.3f}\".format(wer_metric.compute(predictions=results[\"pred_str\"], references=results[\"text\"])))"
      ],
      "metadata": {
        "id": "VaJCwtWTOeLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## push to repo"
      ],
      "metadata": {
        "id": "086-JZMRZVV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install git-lfs tree"
      ],
      "metadata": {
        "id": "xG4md4x2ZTyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "xtPX-htouYQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import Repository\n",
        "\n",
        "repo = Repository(local_dir=\"wav2vec2-base-en-in\", clone_from=\"crossdelenna/wav2vec2-base-en-in\")"
      ],
      "metadata": {
        "id": "Ok9A-YwHZdgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save LM processor"
      ],
      "metadata": {
        "id": "eGHXla0HcwTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processor_with_lm.save_pretrained(\"wav2vec2-base-en-in\")"
      ],
      "metadata": {
        "id": "MrjWCKvQcvdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tree -h wav2vec2-base-en-in/"
      ],
      "metadata": {
        "id": "OT9bfUgOc9nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert arpa to bin to reduce size"
      ],
      "metadata": {
        "id": "maQ1J0_mdVNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kenlm/build/bin/build_binary wav2vec2-base-en-in/language_model/5gram_correct.arpa wav2vec2-base-en-in/language_model/5gram.bin"
      ],
      "metadata": {
        "id": "1km2YQWBdmG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, it worked! Let's remove the `.arpa` file and check the size of the binary *5-gram* LM."
      ],
      "metadata": {
        "id": "QjGASOf2Ypd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm wav2vec2-base-en-in/language_model/5gram_correct.arpa && tree -h wav2vec2-base-en-in/"
      ],
      "metadata": {
        "id": "zPaT3g-GYo69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Push repo with LM to hub"
      ],
      "metadata": {
        "id": "8vcXnDRBeEPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!cd wav2vec2-base-en-in\n",
        "#!cd \\content\n"
      ],
      "metadata": {
        "id": "M-pSe1KHf4wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!transformers-cli login\n",
        "#transformers-cli repo create your-model-name"
      ],
      "metadata": {
        "id": "C_-5JKwVfLaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://crossdelenna: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@huggingface.co/crossdelenna/wav2vec2-base-en-in\n"
      ],
      "metadata": {
        "id": "EFVshJ5mjgH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/wav2vec2-base-en-in\n",
        "!git lfs install\n",
        "#!git config --global user.email \"nifty.emini@gmail.com\"\n",
        "#!git config --global user.name \"crossdelenna\"\n"
      ],
      "metadata": {
        "id": "19wu0zKjhDc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n",
        "!git commit -m \"LM decoder\"\n",
        "!git push"
      ],
      "metadata": {
        "id": "_u-pjgW-jBUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!repo.git_pull()"
      ],
      "metadata": {
        "id": "XKfGxFMChuXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo.push_to_hub(commit_message=\"Upload lm-boosted decoder\")"
      ],
      "metadata": {
        "id": "eGFMhqBXeMaO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}