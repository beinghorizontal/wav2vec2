{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/beinghorizontal/wav2vec2/blob/main/finetune_crossdelenna_medium_cross_en.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILN_e_Hoq08R"
   },
   "source": [
    "# Install required packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0v4652Rsq3Qk",
    "outputId": "3e5f25f5-5549-4144-d850-d12a48426b12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.system(\"pip install datasets transformers jiwer evaluate huggingface_hub tokenizers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYL6iMsTqkzG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import random\n",
    "import librosa\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "from transformers import (\n",
    "    WhisperFeatureExtractor,\n",
    "    WhisperTokenizer,\n",
    "    WhisperProcessor,\n",
    "    WhisperForConditionalGeneration,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    ")\n",
    "from google.colab import drive, output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dl499udLqtq7"
   },
   "source": [
    "# Check GPU availability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cqkDMLuOqx8Q",
    "outputId": "04a6f4c2-b04c-4f51-85a1-0d2972453b03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 22 19:59:37 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   45C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpu_info = os.popen(\"nvidia-smi\").read()\n",
    "if \"failed\" in gpu_info:\n",
    "    print(\"Not connected to a GPU\")\n",
    "else:\n",
    "    print(gpu_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jcdd6sAGq7H8"
   },
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525,
     "referenced_widgets": [
      "66698f13e75042a3818afe7008519538",
      "d374ac5b31d54607a07cf2c7439b649f",
      "abc323a8f11e4ec6a4e52b39becc55e4",
      "3451b4359ba348e5bab4a65b29c047a9",
      "35456fa730544f349ea59a3f791d8fc8",
      "2d8347f81c504dc89f62153771b3b55b",
      "31269a70c7154dedb2875a37f8538be3",
      "ce2d620f251d44faaab2af1bb9c7b8a5",
      "6cc00d0b00414c668a1805d7a8d30716",
      "2423ee2879234c1a844fa3489fc1a099",
      "d1dd03f6442e4d759709fa51ec8e7ea8",
      "d8ba0e322e884f56b2f58d1aac1f7876",
      "1b064b45655648aba48f8bf12ccc7aa1",
      "74ee65766d5142bb8df851c961dc0965",
      "99d4fa5e16dc448daa60c9346d28d135",
      "e0143026339c4ef1a85410ee8c9a8bed",
      "f39573fed3f44aa29861c6865b9185e9",
      "2c1bfdb4378d4c37aec4200a6fb8abf0",
      "63fb8b21958d4b36afa115d062786855",
      "e3938529a8a24f01b0a1fcf76391aa51",
      "249e58c4e7e44e52b9105ca88fb67b99",
      "6210892678a445388a0873aa848a2003",
      "d83b83bc23054e6f84734e97dcb12c75",
      "8424ee7bed8540c5a1e65e2208227403",
      "976ba866855e496aa3f95924c8aa9735",
      "46261f2869634c0d834eff72983dc45f",
      "0f40d5c5a5b141aa96958cd03703ed2e",
      "26762fe9bd134e83b7517839c010285d",
      "9d9c3fc8aa6b4fd694918c71197d8a2d",
      "ba6ecf816577463585f86e55c16efbe2",
      "04dce1340a1a4d069917a2a5d9e24120",
      "8cdd58b97df042bb93bd07df48672732",
      "57e5301f8fab4a7e8743904b9faca328",
      "9ad7580ca7e64f27a5935a03b9f32f05",
      "d5629969321043c3bae566635127f8d0",
      "2cc4e2a6680b4ecf83d858c648249379",
      "4ccceb0a7869455a9a1aa623287d2c6e",
      "91d090356f334954a2c7fadcc0e538a1",
      "3c216b146efb4c04bd99959f89de20b3",
      "2f9e660d11dc4bc3ae16c9a917e5d421",
      "13389a63c5f145cf8b0c9e81bb35df2a",
      "af2cb79d638f4c85b4181fc25a64cfb1",
      "88491c84607e4201af2c3d688efe936a",
      "684c6558553c4439845cfe82042afa32",
      "e38168172a28468e8dc65eaca14c710c",
      "58554a37008d408793e79090068ce1f1",
      "bb70eb9c3f4a4f5fa1635bf8acc703f8",
      "2a791cd71ee542548f45a6bad7dbe3b0",
      "234480994c4740558211801ec92749d9",
      "c2a9a672988f4d2688527c3206b57713",
      "79f3ee9669584bc6bf5c17f27e034f85",
      "97c0625406db4ff6b40f250a2ce78d11",
      "b799c0318af64e6987157caba6d3dc8e",
      "b3a9d16dd9df4a90b12e860699558aa4",
      "73b8cf978b3548e99ff21369fbbafb3e",
      "56a7c14533de439a94c494b77b634361",
      "247ff0a64f44401b98fbdadd4843ddfd",
      "9be7250f3b1c4b2ab615604d4e2824a1",
      "97f40c4e2aa7416283be158747662693",
      "6a6e16453e5743f2ba0c1ad857f2416e",
      "1d47ddc866a643ee90834d5bfe280f5e",
      "49cbb93e8c9d496c9a7de0a73af44950",
      "148e0e0f68b64268ab1bf4d618c65229",
      "0349d97ee62c41c3a57aa7a43a07b2b4",
      "0a68d2f81d0c4f3097e0eb91b9645d14",
      "6f2f38ed741e4e709110f5d5e0fe3fb9",
      "f55bcb9e2a3f40b7985a93240a48d8a3",
      "58bcad50bcba4dc59f24c2d0a90108ac",
      "5511711ec9eb460db5b050eaaa447556",
      "f1302fc0e86d4d4798eede40d865ab18",
      "eafd681573eb4edf9bbf7968ceb5f588",
      "e9c4eb18b6e84c3190cf20d9045eba82",
      "dea7c030970f465cadd0e2e8d13908cf",
      "f3a1dd975dc14070b99827689246167c",
      "a714a460846a48bf9a602c341bfd7c38",
      "bbdbebedbf6b4b51bf820dea8dbfe64d",
      "dc6570948e3a4bc3b08a4f166a03158a",
      "567fcbbfb8ad488eabaf184de0f76081",
      "7fa6e5df66d5472783ed4af519302358",
      "07d12f5949b144d7a39cd9c73820e149",
      "6cc0e5ab0d1647448b5f97e44a835535",
      "65c290d2840b456599a357913f7ac666",
      "663ac7eaf73f4e95848f27d907648970",
      "b4c229ea51a94dca874c227272e650b4",
      "3e69e7f03dcb4c2f9c60bcb27ee3f612",
      "fdedacbf3e1c4030a67f2996aa841f35",
      "fa72446725ab436aa91b3c900c7109e6",
      "80b67ddcca1f42e5aa6989e5c31fa3c7",
      "7df5279314064c7d9b493333ab47d1bc",
      "3e9831b1ead64c8da518a1c02251086c",
      "4804d2aeeee240029a0aab421a7f166a",
      "0b97cb95265448aa9fc5f0bee45744ca",
      "88c68ae479be4fb08efc58d595039d15",
      "d60f34e15b1945acbb4d3d572bb9e645",
      "379d8fa632c347509684f411eaa538ae",
      "87d1528ed2ad40818b757ff3edf464e2",
      "025e7b257eba46c8973a13fbd3688c83",
      "5ec37d74928a40a38363ed67743aaea0",
      "6a8a232602f244229cfef6cd53f59375",
      "3bf1aed1bd394ed6a3a5b301ec20d67f",
      "7bfaec96579441afa5fe177179632283",
      "25bdb403f69c4772a2e547e42f94bc27",
      "0f6a0ab28775499cbc70a75b61b5e956",
      "f050a145aef640ccb2dd25e5b39126f3",
      "ac309820320b44938a8d1fb34f9dade7",
      "6474ca5edb4840e99a043e45c8a863ab",
      "4db5ce6d31a14d6dbb251afe7ecc49b1",
      "e20950d13cf14e1f95fa604dbc9de524",
      "8f72fd59f6ad4d02b6d7478263d9bdda",
      "8bff101a0e3a419a85a02d0ff566f70d",
      "b693f79ba03d4155841c89dc764a865f",
      "e423a9cbbe7e4699836949d3a869a555",
      "3c6da042386e47cbb90284ccc926ccd7",
      "d35e1aedde714f378f3c2006a1b4cdfe",
      "4367d343ddb044cca99d57796b7071d3",
      "f1227a31569c4b2db404903ba78cd5c1",
      "0a983c44c963435fb386bd5a2d1d628f",
      "dc91f3032d9640538d745eed9dd01363",
      "6dfe1c4d9b024544b06c0bf4e8be808f",
      "bfc76c4832e44badaa865b983ac32812",
      "9102e4c2f32343ecbfe27eb62741f308",
      "59ee3dc1b0fe4d62995144a70b71897e",
      "0b5e6d89092d4bd78bdae713a0b4b229",
      "fceefcffa7454dba886403cbf2af657b",
      "976ef513b7eb4dcfbeafbc3e3b961afa",
      "c18aa0a21fbb433d9c007f6d46d22432",
      "f2a7c7ca33374773b067914e8048aea1",
      "e85586ce329247bfb1cf72eb9ed88e91",
      "5fc632ef6e5f457bb430c9eb543de138",
      "4f3e03c1aa074f3293b7b21e0eb5e001",
      "795d40a7434e405196de68039fdae684",
      "d0923f2fae84494d9aaba12556d05445",
      "486f644845024cbcbc6f10917d6271df",
      "7e1d7e18765047248e15e8657607a5cf",
      "a057922697b64bb98869d64b5c0e3970",
      "5072b4f2f104407790386d9a8012de2f",
      "f30a391ba18f4642befc51954cb4779c",
      "83ab6e1d176748b6979672c6b962f953",
      "1ca75ee7055f49db807f943428208a72",
      "37e8da37124e47e1822c3b568e945ab0",
      "d72aede9f3824ef799389cf92a795cbe",
      "cb70fccb23a7439dad36510015438bae"
     ]
    },
    "id": "_Dw_CMA9q9u4",
    "outputId": "7d628937-dc23-428c-d998-51d020cd103b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66698f13e75042a3818afe7008519538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/538 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6210892678a445388a0873aa848a2003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00010-d604df9729955191.parquet:   0%|          | 0.00/377M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e5301f8fab4a7e8743904b9faca328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00001-of-00010-502280478f70c677.parquet:   0%|          | 0.00/465M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684c6558553c4439845cfe82042afa32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00002-of-00010-3432ad2975db91f7.parquet:   0%|          | 0.00/480M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b8cf978b3548e99ff21369fbbafb3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00003-of-00010-2d8c01606d2bc32c.parquet:   0%|          | 0.00/362M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2f38ed741e4e709110f5d5e0fe3fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00004-of-00010-a689ae9436e9183e.parquet:   0%|          | 0.00/260M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6570948e3a4bc3b08a4f166a03158a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00005-of-00010-8d14c060151dbf8a.parquet:   0%|          | 0.00/259M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b67ddcca1f42e5aa6989e5c31fa3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00006-of-00010-a76c7af01cf155f0.parquet:   0%|          | 0.00/260M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8a232602f244229cfef6cd53f59375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00007-of-00010-a75098cb73c162f5.parquet:   0%|          | 0.00/262M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bff101a0e3a419a85a02d0ff566f70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00008-of-00010-746a2e779a8e92e5.parquet:   0%|          | 0.00/264M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9102e4c2f32343ecbfe27eb62741f308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00009-of-00010-e88ae7ef704d923e.parquet:   0%|          | 0.00/249M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb70fccb23a7439dad36510015438bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "timit = load_dataset(\"crossdelenna/alex_3110_2025\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GT2Ou0_srBxz"
   },
   "source": [
    "# Split dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t081hsDyrFmN",
    "outputId": "4664a876-a381-4b6a-8a9c-9e96578b4ba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['audio', 'text', 'input_features', 'labels'],\n",
      "    num_rows: 2760\n",
      "})\n",
      "Dataset({\n",
      "    features: ['audio', 'text', 'input_features', 'labels'],\n",
      "    num_rows: 344\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "num_rows = len(timit[\"train\"])\n",
    "num_test_rows = num_rows // 9\n",
    "num_train_rows = num_rows - num_test_rows\n",
    "timit_train = timit[\"train\"].select(range(num_train_rows))\n",
    "timit_test = timit[\"train\"].select(range(num_test_rows))\n",
    "\n",
    "\n",
    "print(timit_train)\n",
    "print(timit_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HIZkRUfrKYJ"
   },
   "source": [
    "# Load Whisper components from Hugging Face Hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401,
     "referenced_widgets": [
      "015c2c36e7d84b899474c498236e7604",
      "a9345757fd50482a96815cc24400e1a9",
      "4d7f4195683e4c3ab214529fe9e6f6fa",
      "dcffa3bab467465685ceafba300e6462",
      "b36d250952034d4ba4b38c0e93d7738a",
      "a159bb48a0ab410aa2591f3c7cc2802a",
      "20e7a7314f234901b1378fcbc64b437c",
      "b0ad1355e9f5416f9af076e35361fc43",
      "2a914b1e2c944b209b1b3a19d26df97d",
      "27909e02822a419ba75aafcc5eabf21f",
      "51b38eb66a1d4760adc489c1026fd2f3",
      "7f34f79f4a6e4efb94babc14a6cc60ac",
      "fefca5389298484f92b1ffb8e8f71b14",
      "8ffd1ccb4d974208b287e47f8708ed2a",
      "0e74349fd2054e6298b1efee1a573f3f",
      "035503a3005f42d99e8e9243fe33774b",
      "120d38711e1f41a092612f3e3926f61c",
      "ad59b1f46cb84b679c430480aca21125",
      "9dbd76b1ca7b4e5a9b9d051022ba9cbd",
      "f5a6f08a31074266864d14f5146fe11b",
      "393b42f9b0f0410a83569aeaa4530ebd",
      "58037ec96bce4f7090aca8665e875e1c",
      "bf7f51fe270249cc97ff0677e1261b8d",
      "83a99addb9804fdd9be35b32e8b05c80",
      "de0f9f2b1010453499695b6b8ad97772",
      "55f94e7b60564e628ffe53c0a76baef8",
      "af8ddb188c6041e9ac830ae207bdcc75",
      "38683833950a48aaaba33b0127d3ac61",
      "41f227d2fc0740cdb345b0ae6ee0911d",
      "0cb559cba65c4f419b98e9c539f1b4a5",
      "8ed6bcc9bce2401fa65c34dcfd097ea3",
      "fc1083abeda4496ea1c760c3a784906a",
      "ab9355925e854d1dbb861b8f364a934f",
      "54a2cdf40f0c49b49c589d5d05347659",
      "a9f02e9264774fd7af0c02e37a3b4b4c",
      "a04c058fd4d24109bb212d89d544d182",
      "e9a1db70ad484f3993116b2c049b3752",
      "850d065234ad41109274775e3b015b6a",
      "632dd0556d5e4810905c2de6f25453a0",
      "d2fb4f64d5ed4d538ac91d0543109410",
      "858a74bdf8b543a9bcd2792b562eb5d7",
      "422514937fa74035992e1361853375da",
      "70665b737b4c4ca288930882f1eeba7b",
      "2f8f98a82cec45a88620b8b871b60738",
      "db6161b1e90f4fd0aef2a38d3aad8a6f",
      "336c9bef69b349cc8a2325f9d3c9a257",
      "8ece4e41b3f945ae8666691f59d81279",
      "d44a559dd4ec4aeab096f3605d7a6a8d",
      "86a1215ceed04e25baacf38319efc221",
      "18c04f29659745a3942490b9b3f73b40",
      "49cea1c5caf349608592c28265223acb",
      "f190eaa5fd94423daf1bb6947feeb9f8",
      "5e9dd325e3df4287a48bc7996bae17b8",
      "24533206464c42389a9b11de05ccc01d",
      "8d1a71a192cd4762b441872698e3d158",
      "c498289dc52f4d16b39b032eb5cbe760",
      "7dd1295a63a54db79b4b975a39591fb4",
      "3ce9331b762d47f785549fed0a6567f1",
      "84c4d67a705c4bef9f398abddf541988",
      "7db915d6c2b6474d8592fbe55969a22a",
      "ae7e9b6a89364b089fccfb4ad8b3e485",
      "8041853eaed840e9b2fd1372b3b30850",
      "8d68345f6c514f6b84c1895752318852",
      "73173cdb4e6e47a8a59ab6c851af5829",
      "7c0347b9590545328c2b3a41fbc62fa8",
      "49978a59690d427ea2444596afeb3e8a",
      "94310c4bcc8c488081408920fe128521",
      "db478c3025474c35aa8811b82051830e",
      "2b8e23767f164b58928b0cf6a853f560",
      "2596394293fa444c967cee4a2dfa2248",
      "079477017a534f5dba38959184f3f2e8",
      "d3e20740cd33434f8a5ac3671120a911",
      "b0eb57090ab84654bc16c941434e8cec",
      "17e740edda7c4b1e801c88aef6d4629a",
      "13185b16feb94300a6f70667bcf46d27",
      "50469f7c1724469fb271e3c04984c616",
      "1fc2e435eda54ad6ac087f41e739d584",
      "82e00e57e4c2444bbd1bd9d9b22fef59",
      "d91e9b1ddd584128bcac35ce5c06ed84",
      "01f6b1f857f1458eb610ae31c84bd430",
      "68aa6d11011043578e3ed29a672b22cf",
      "29308672856f466884427f7540b383d1",
      "29526f49c59a4cafba6a5c9379054a76",
      "07d4fdaeaa93490c97a60c7ae773a8db",
      "d35508222c8b4dd3bfe21da194025429",
      "15898864b0334c98980074ba86843cfc",
      "379fde4af8954204928500f0503b4986",
      "ad750f4db7584839807e657d5cbe821d",
      "e0732f045734443a8397e41b19120f16",
      "d2b51fad4f484fb4b1d618d160787750",
      "6af1e5fa891f48de94989704301f903f",
      "d756ccccbb8843598d13204f71389083",
      "77aa337beecc442db4fe1d30064ca22d",
      "f8e8755ed8144232b8fbb08335fdc90f",
      "2f4a5a47a6e94aea982e62ba76136430",
      "1e7c5f00dcb445c2b87cb7ad1c190819",
      "51850be7ac524dc2b7356ab5c30b78c0",
      "b87214fc68674faf9094df4d69c62555",
      "44c1e092034748899a467544f0772db8",
      "161a6b46e41144b1b2c106393b6e7df1",
      "f096db5f6fb84f0eac2cf242bd5ea544",
      "819aa63c55194cfcb45744ccb09f8c14",
      "33e0976b830c4bbfbd5f3213751a8180",
      "7c1914b955d34496b30ac9920926e3aa",
      "610f8f331ad94fd9bb051d6cf12e4dc0",
      "d773dfa7ede7472b9f6fa4895ef32a06",
      "457bfbadafc14ad88acbfc1b615fc4f5",
      "2f6d4adf413444a1a1d9e8194bfa7b04",
      "4ebb35ac04774dbda60b0bacc148f966",
      "446d98873315493da4e0b67a645444dd",
      "39dc035042214db69abfe89ba46b8586",
      "27a0ffc0072340a89c1898b5d836477a",
      "fee816c0a5eb4aa4b206bbc69e2bf183",
      "6ba58ceb40894dc985f8d647558b87c1",
      "3f29ff7d1fdc4a62b59e2f8ab892dbe2",
      "e539fed5a7174e5d8495859c13c4da87",
      "be9dff5cfc2742ecbd1bd25c3707bd92",
      "f58a3467c22b4869b51f443f49758409",
      "01ee996ef1e445d989173cfacb0674e7",
      "f4c2b1e45d8a4908bc91de20c5cee363",
      "4fcba6cce379481db40b2dd1a1c64360",
      "8d36fcccf319490ea1299797c30a06d2",
      "0c6b2f04d0464c428a002dcee2cefe18",
      "496311963887402faa163bfde69e3098",
      "bf1e77762d3d4245808cbb5e7051554e",
      "ea34c826441e435695d42ca29e2ac373",
      "386abdcc10df4edba3c965787b9bff21",
      "9aa36835d5fa41b3bb3c2d2038bf3c58",
      "7653b623cf194c4fa93564643ed9df5d",
      "fdca504d65574c0e9ee0d2dad8a7be29",
      "b0c278e392164c7083244d39fb30ecc7",
      "5e80a226b0034b0eba936e9673d7d8a9"
     ]
    },
    "id": "xCPKqQqGrOnK",
    "outputId": "17936aa1-da30-40d3-a18d-0cdce0f44adb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015c2c36e7d84b899474c498236e7604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/339 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58037ec96bce4f7090aca8665e875e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/805 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9355925e854d1dbb861b8f364a934f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8f98a82cec45a88620b8b871b60738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.41M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1a71a192cd4762b441872698e3d158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49978a59690d427ea2444596afeb3e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc2e435eda54ad6ac087f41e739d584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad750f4db7584839807e657d5cbe821d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c1e092034748899a467544f0772db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446d98873315493da4e0b67a645444dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fcba6cce379481db40b2dd1a1c64360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e80a226b0034b0eba936e9673d7d8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/1.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature_extractor = WhisperFeatureExtractor.from_pretrained(\"crossdelenna/whisper_med_alex.en\")\n",
    "# tokenizer = WhisperTokenizer.from_pretrained(\"crossdelenna/whisper_med_alex.en\", language=\"English\", task=\"transcribe\")\n",
    "# processor = WhisperProcessor.from_pretrained(\"crossdelenna/whisper_med_alex.en\", language=\"English\", task=\"transcribe\")\n",
    "\n",
    "# feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-medium.en\")\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\n",
    "    \"crossdelenna/whisper_med_alex.en\"\n",
    ")\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\n",
    "    \"openai/whisper-medium.en\", language=\"English\", task=\"transcribe\"\n",
    ")\n",
    "processor = WhisperProcessor.from_pretrained(\n",
    "    \"openai/whisper-medium.en\", language=\"English\", task=\"transcribe\"\n",
    ")\n",
    "\n",
    "# model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-medium.en\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\n",
    "    \"crossdelenna/whisper_med_alex.en\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EATa2syFlK24",
    "outputId": "2cbd1b39-f517-4238-d478-cf6c8d73376e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "git is already the newest version (1:2.34.1-1ubuntu1.12).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 21 not upgraded.\n",
      "Cloning into 'whisper_med_alex.en'...\n",
      "remote: Enumerating objects: 2514, done.\u001b[K\n",
      "remote: Counting objects: 100% (2511/2511), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1739/1739), done.\u001b[K\n",
      "remote: Total 2514 (delta 793), reused 2457 (delta 772), pack-reused 3 (from 1)\u001b[K\n",
      "Receiving objects: 100% (2514/2514), 1.14 MiB | 1.84 MiB/s, done.\n",
      "Resolving deltas: 100% (793/793), done.\n",
      "Filtering content: 100% (62/62), 7.33 GiB | 38.21 MiB/s, done.\n",
      "Files in the cloned repository: ['.git', 'added_tokens.json', 'model.safetensors', 'last-checkpoint', '.gitattributes', 'tokenizer_config.json', 'special_tokens_map.json', 'tokenizer.json', 'training_args.bin', 'README.md', 'generation_config.json', 'preprocessor_config.json', 'normalizer.json', 'runs', 'config.json', 'vocab.json', 'merges.txt']\n"
     ]
    }
   ],
   "source": [
    "!apt-get install git\n",
    "\n",
    "# Clone your Hugging Face repository\n",
    "!git clone https://huggingface.co/crossdelenna/whisper_med_alex.en\n",
    "\n",
    "# Verify the cloned repository\n",
    "import os\n",
    "\n",
    "print(\"Files in the cloned repository:\", os.listdir(\"./whisper_med_alex.en\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUsyaFgQrRWR"
   },
   "source": [
    "# Data collator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EH11dxpnrVEa"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(\n",
    "        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [\n",
    "            {\"input_features\": feature[\"input_features\"]} for feature in features\n",
    "        ]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(\n",
    "            labels_batch.attention_mask.ne(1), -100\n",
    "        )\n",
    "\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uHZyQSnrX-8"
   },
   "source": [
    "# Evaluation metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "f6bb5e27a9bd4d8bab1f24a952939a1b",
      "eaa4fef159b14e578456f24fe05214af",
      "5b7391558034452d9cf9566dc9e0618f",
      "c3e940e9716d4c20b581a06e7ed09bc2",
      "4e0bb2fbe0604316a5a7b820ddad8c89",
      "9249982cff154d15b7679d0545dc0d74",
      "bc3bdd864aa448be99709b7e883d9a4b",
      "dc0712a4d06246d4af6381026fa7959a",
      "a4723c9a7a144361b2e9a5074b0ef034",
      "58dc931a13e848b388dcbaaf30c49f66",
      "1216a77f498f428381f39fc0a6d645f8"
     ]
    },
    "id": "ZYAcKqV2rbBS",
    "outputId": "4f9a42ba-ef60-4b6c-e52a-421947f29c22"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6bb5e27a9bd4d8bab1f24a952939a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = evaluate.load(\"wer\")\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "    return {\"wer\": wer}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDhp5NLWrdTs"
   },
   "source": [
    "# Freeze layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CncGzhDDrhEl"
   },
   "outputs": [],
   "source": [
    "def freeze_whisper_layers(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    try:\n",
    "        encoder_layers = model.model.encoder.layers\n",
    "        for layer in encoder_layers[-10:]:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = True\n",
    "    except AttributeError:\n",
    "        print(\"Could not access encoder layers\")\n",
    "\n",
    "    try:\n",
    "        decoder_layers = model.model.decoder.layers\n",
    "        for layer in decoder_layers[-10:]:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = True\n",
    "    except AttributeError:\n",
    "        print(\"Could not access decoder layers\")\n",
    "\n",
    "    try:\n",
    "        model.model.encoder.layer_norm.requires_grad = True\n",
    "    except AttributeError:\n",
    "        print(\"Could not access encoder layer norm\")\n",
    "\n",
    "    try:\n",
    "        model.model.decoder.layer_norm.requires_grad = True\n",
    "    except AttributeError:\n",
    "        print(\"Could not access decoder layer norm\")\n",
    "\n",
    "    for name, module in model.named_children():\n",
    "        if \"proj\" in name or \"head\" in name or \"classifier\" in name:\n",
    "            for param in module.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = freeze_whisper_layers(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbwtIjUor480"
   },
   "source": [
    "# Verify trainable parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sgZXKBHFr3ZB",
    "outputId": "0542f93d-796d-4c5c-c6c0-29cb6b694a69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 763856896\n",
      "Trainable parameters: 347006976\n",
      "Percentage of trainable parameters: 45.43%\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n",
    "print(f\"Percentage of trainable parameters: {trainable_params / total_params * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBYnd1f5r-go"
   },
   "source": [
    "# Training arguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ds4HKZHpXkJ",
    "outputId": "c93d2cf3-da37-4abc-ea7c-dc0bfed84b6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step at the last checkpoint: 4200\n",
      "New maximum training steps: 5101\n"
     ]
    }
   ],
   "source": [
    "# Define the checkpoint path\n",
    "checkpoint_path = \"/content/whisper_med_alex.en/last-checkpoint\"  # Replace with the actual checkpoint folder name\n",
    "import json\n",
    "\n",
    "# Read the trainer_state.json file\n",
    "trainer_state_file = os.path.join(checkpoint_path, \"trainer_state.json\")\n",
    "with open(trainer_state_file, \"r\") as f:\n",
    "    trainer_state = json.load(f)\n",
    "\n",
    "# Extract the global step\n",
    "global_step = trainer_state[\"global_step\"]\n",
    "print(f\"Global step at the last checkpoint: {global_step}\")\n",
    "\n",
    "# Define the additional steps\n",
    "additional_steps = 901\n",
    "\n",
    "# Calculate the new maximum training steps\n",
    "new_max_steps = global_step + additional_steps\n",
    "print(f\"New maximum training steps: {new_max_steps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wIznLJGgsOpF",
    "outputId": "ec34fbd0-bda0-4bf9-d1d6-6a3bc6df4c2f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "<ipython-input-14-e8bf6e460b5c>:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-medium.en\",\n",
    "    per_device_train_batch_size=24,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=1e-6,\n",
    "    warmup_steps=10,\n",
    "    max_steps=new_max_steps,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=20,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=300,\n",
    "    eval_steps=300,\n",
    "    logging_steps=300,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=True,\n",
    "    hub_strategy=\"checkpoint\",\n",
    "    hub_model_id=\"crossdelenna/whisper_med_alex.en\",\n",
    "    hub_token=\"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\",\n",
    "    resume_from_checkpoint=True,  # This will resume training from the last checkpoint\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=timit_train,\n",
    "    eval_dataset=timit_test,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBD4etzmSJGr"
   },
   "source": [
    "# Custom Seq2SeqTrainer to use sampled validation subset. Default random sample size is 300 from test data for faster evaluation at each eval_steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2OrtXhDsQ1i"
   },
   "source": [
    "# Save processor and tokenizer locally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RM2awF4KsTS9",
    "outputId": "041b731a-8d82-4b10-f8a2-90a1066875b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./whisper-medium.en/tokenizer_config.json',\n",
       " './whisper-medium.en/special_tokens_map.json',\n",
       " './whisper-medium.en/vocab.json',\n",
       " './whisper-medium.en/merges.txt',\n",
       " './whisper-medium.en/normalizer.json',\n",
       " './whisper-medium.en/added_tokens.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.save_pretrained(training_args.output_dir)\n",
    "tokenizer.save_pretrained(training_args.output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbeXAXXqsWMD"
   },
   "source": [
    "# Train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "jxAifpyNsZhH",
    "outputId": "324521c4-5e73-4bec-e33b-c12a22542f6f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/trainer.py:3441: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/trainer.py:3105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4807' max='5101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4807/5101 1:14:33 < 36:13, 0.14 it/s, Epoch 41.79/45]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>5.332704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>5.370458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = (\n",
    "    \"/content/whisper_med_alex.en/last-checkpoint\"  # Specify the path to the checkpoint\n",
    ")\n",
    "\n",
    "trainer.train(resume_from_checkpoint=checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gF8qXTNssbUG"
   },
   "source": [
    "# Push to hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S6FDczc1sd7Q"
   },
   "outputs": [],
   "source": [
    "trainer.push_to_hub()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJ_t0wjfsgtU"
   },
   "source": [
    "# Save model, processor, and tokenizer locally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T-t9yD6MskMf"
   },
   "outputs": [],
   "source": [
    "processor.save_pretrained(training_args.output_dir)\n",
    "tokenizer.save_pretrained(training_args.output_dir)\n",
    "feature_extractor.save_pretrained(training_args.output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AK77oX0-smX8"
   },
   "source": [
    "# Push processor and tokenizer to the Hugging Face Hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BBH0UhodqYGC"
   },
   "outputs": [],
   "source": [
    "processor.push_to_hub(\n",
    "    \"crossdelenna/whisper_med_alex.en\",\n",
    "    token=\"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\",\n",
    "    commit_message=\"Upload processor\",\n",
    ")\n",
    "tokenizer.push_to_hub(\n",
    "    \"crossdelenna/whisper_med_alex.en\",\n",
    "    token=\"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\",\n",
    "    commit_message=\"Upload tokenizer\",\n",
    ")\n",
    "feature_extractor.push_to_hub(\n",
    "    \"crossdelenna/medium_cross.en\",\n",
    "    token=\"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\",\n",
    "    commit_message=\"Upload feature extractor\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
