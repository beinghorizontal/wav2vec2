{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quick_finetune_large-en-in-lm.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f3159768797b4584a00e0cab0f1dfd70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3eb5a5365b445d697c0ca457ec44f84",
              "IPY_MODEL_592b7e6270c243bcaa64aaae8db428d0",
              "IPY_MODEL_6aa2e183e1dc4adb91886a5b9949b552"
            ],
            "layout": "IPY_MODEL_a198ce9dccdc43b8b0ffd981bff79bc5"
          }
        },
        "a3eb5a5365b445d697c0ca457ec44f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66b3612d03044d16878e36496174541c",
            "placeholder": "​",
            "style": "IPY_MODEL_2efc6992e01643e49935fb6bd63b84b9",
            "value": "Downloading builder script: 100%"
          }
        },
        "592b7e6270c243bcaa64aaae8db428d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_927ecc2b44e34d5a9ab43f7cfa5aa63b",
            "max": 4485,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecbc7dda0d394dc8b9dce5d9b30ab17b",
            "value": 4485
          }
        },
        "6aa2e183e1dc4adb91886a5b9949b552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b79505540a244e05951b188f30a06a6d",
            "placeholder": "​",
            "style": "IPY_MODEL_758fc74e25e447cd93b7c60243a85c71",
            "value": " 4.49k/4.49k [00:00&lt;00:00, 297kB/s]"
          }
        },
        "a198ce9dccdc43b8b0ffd981bff79bc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66b3612d03044d16878e36496174541c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2efc6992e01643e49935fb6bd63b84b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "927ecc2b44e34d5a9ab43f7cfa5aa63b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecbc7dda0d394dc8b9dce5d9b30ab17b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b79505540a244e05951b188f30a06a6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "758fc74e25e447cd93b7c60243a85c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beinghorizontal/wav2vec2/blob/main/finetune_whisper_en_in.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "thdGplBzw5Xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "ZgsoCDhxL8wX",
        "outputId": "0decf562-3a13-478b-b3c7-bb592e1ad3ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 20 16:49:09 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import datasets\n",
        "!pip install datasets\n",
        "import datasets\n",
        "timit = datasets.load_dataset(\"crossdelenna/whisper_data_merge2\", use_auth_token='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')"
      ],
      "metadata": {
        "id": "aqmpHpyDIlPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_rows = int(len(timit['train']))\n",
        "num_test_rows = int(len(timit['train'])/7)\n",
        "num_train_rows = num_rows - num_test_rows\n",
        "timit_train = timit[\"train\"].shuffle(seed=42).select(range(num_train_rows))\n",
        "timit_test = timit[\"train\"].shuffle(seed=42).select(range(num_test_rows))\n"
      ],
      "metadata": {
        "id": "dEBV5p-vIdx-",
        "outputId": "56221eb6-a004-4ed3-e7b4-d630c8227f0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/crossdelenna___parquet/crossdelenna--whisper_data_merge2-ad354d561af76341/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-cf5af7b0cde83f10.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timit_train"
      ],
      "metadata": {
        "id": "yZg6TeS2MH5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timit_test"
      ],
      "metadata": {
        "id": "EtgFoypLM2al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "#!unzip \"/content/drive/MyDrive/checkpoints_large.zip\" -d \"/content/\"\n",
        "#!unzip \"/content/drive/MyDrive/checkpoints_large.zip\" -d \"/content/\""
      ],
      "metadata": {
        "id": "fYAXooWRJJne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "#!pip install datasets==1.18.3\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install jiwer\n",
        "!pip install librosa\n",
        "!pip install evaluate>=0.30\n",
        "!pip install jiwer\n",
        "!pip install gradio\n",
        "!pip install bitsandbytes\n",
        "!pip install accelerate\n",
        "\n",
        "\n",
        "from accelerate import PartialState\n"
      ],
      "metadata": {
        "id": "9QLXpnFTJdTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "QVPX-Lkro1Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path to upload checkpoints to drive\n",
        "#from shutil import copyfile\n",
        "#dst = '/usr/local/lib/python3.9/dist-packages/transformers/trainer.py'\n",
        "#src = '/content/drive/MyDrive/trainer_mod_large.py'\n",
        "#copyfile(src, dst)"
      ],
      "metadata": {
        "id": "y7KsYbx1Jn4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!apt install git-lfs"
      ],
      "metadata": {
        "id": "kODiImxmJ7zD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\");\n",
        "     btn.click()\n",
        "     }\n",
        "\n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\");\n",
        "     btn.click()\n",
        "     }\n",
        "  }\n",
        "\n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"Done.\")"
      ],
      "metadata": {
        "id": "WuaRjtflJ-CM",
        "outputId": "ba3b690a-0877-4f69-a897-631ca422b981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              " function ClickConnect(){\n",
              "   btn = document.querySelector(\"colab-connect-button\")\n",
              "   if (btn != null){\n",
              "     console.log(\"Click colab-connect-button\"); \n",
              "     btn.click() \n",
              "     }\n",
              "   \n",
              "   btn = document.getElementById('ok')\n",
              "   if (btn != null){\n",
              "     console.log(\"Click reconnect\"); \n",
              "     btn.click() \n",
              "     }\n",
              "  }\n",
              "  \n",
              "setInterval(ClickConnect,60000)\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load WhisperFeatureExtractor\n"
      ],
      "metadata": {
        "id": "PFSffHApkAVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperFeatureExtractor\n",
        "\n",
        "#feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small.en\")\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"crossdelenna/whisper-small.en\")\n"
      ],
      "metadata": {
        "id": "DIELrbALjgG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load WhisperTokenizer"
      ],
      "metadata": {
        "id": "stPDLMChkKzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperTokenizer\n",
        "#tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small.en\", language=\"English\", task=\"transcribe\")\n",
        "tokenizer = WhisperTokenizer.from_pretrained(\"crossdelenna/whisper-small.en\", language=\"English\", task=\"transcribe\")"
      ],
      "metadata": {
        "id": "NjMiBtavkM9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combine To Create A WhisperProcessor"
      ],
      "metadata": {
        "id": "MnfY-n9PlOsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperProcessor\n",
        "#processor = WhisperProcessor.from_pretrained(\"openai/whisper-small.en\", language=\"English\", task=\"transcribe\")\n",
        "processor = WhisperProcessor.from_pretrained(\"crossdelenna/whisper-small.en\", language=\"English\", task=\"transcribe\")"
      ],
      "metadata": {
        "id": "mrdVc2y3lPvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's print the first example of the Common Voice dataset to see\n",
        "what form the data is in:"
      ],
      "metadata": {
        "id": "eMbijzjalj_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(timit[\"train\"][0])"
      ],
      "metadata": {
        "id": "UmqNXTPnlniJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKcEWHvKI1by"
      },
      "source": [
        "**Note**: Currently `datasets` make use of [`torchaudio`](https://pytorch.org/audio/stable/index.html) and [`librosa`](https://librosa.org/doc/latest/index.html) for audio loading and resampling. If you wish to implement your own costumized data loading/sampling, feel free to just make use of the `\"path\"` column instead and disregard the `\"audio\"` column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tborvC9hx88e"
      },
      "source": [
        "import torch\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
        "        # first treat the audio inputs by simply returning torch tensors\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # get the tokenized label sequences\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        # pad the labels to max length\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        # if bos token is appended in previous tokenization step,\n",
        "        # cut bos token here as it's append later anyways\n",
        "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbQf5GuZyQ4_"
      },
      "source": [
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO-Zdj-5cxXp"
      },
      "source": [
        "Next, the evaluation metric is defined. As mentioned earlier, the\n",
        "predominant metric in ASR is the word error rate (WER), hence we will use it in this notebook as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xsux2gmyXso",
        "outputId": "f1d55599-7c36-4860-9cc0-d6ce2355d481",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f3159768797b4584a00e0cab0f1dfd70",
            "a3eb5a5365b445d697c0ca457ec44f84",
            "592b7e6270c243bcaa64aaae8db428d0",
            "6aa2e183e1dc4adb91886a5b9949b552",
            "a198ce9dccdc43b8b0ffd981bff79bc5",
            "66b3612d03044d16878e36496174541c",
            "2efc6992e01643e49935fb6bd63b84b9",
            "927ecc2b44e34d5a9ab43f7cfa5aa63b",
            "ecbc7dda0d394dc8b9dce5d9b30ab17b",
            "b79505540a244e05951b188f30a06a6d",
            "758fc74e25e447cd93b7c60243a85c71"
          ]
        }
      },
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"wer\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3159768797b4584a00e0cab0f1dfd70"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
                }
              }
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XZ-kjweyTy_"
      },
      "source": [
        "def compute_metrics(pred):\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    # replace -100 with the pad_token_id\n",
        "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "\n",
        "    # we do not want to group tokens when computing the metrics\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"wer\": wer}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# #dics = os.listdir('/content/drive/MyDrive/wav2vec2-base-en-in/wav2vec2-base-en-in')\n",
        "# dics = os.listdir('/content/wav2vec2-large-eng-ind')\n",
        "# if dics[0] == '.ipynb_checkpoints':\n",
        "#   dics=dics[1:]\n",
        "# match = [t for t in dics if 'checkpoint' in t]\n",
        "# model_url = '/content/wav2vec2-large-en-in/'+match[0]\n",
        "# print(model_url)\n"
      ],
      "metadata": {
        "id": "cNjNj9wz7rzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7cqAWIayn6w"
      },
      "source": [
        "from transformers import WhisperForConditionalGeneration\n",
        "#model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small.en\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"crossdelenna/whisper-small.en\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.forced_decoder_ids = None\n",
        "model.config.suppress_tokens = []"
      ],
      "metadata": {
        "id": "Ls9zaYSQnwTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./whisper-small.en\",  # change to a repo name of your choice\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
        "    learning_rate=1e-5,\n",
        "    warmup_steps=10,\n",
        "    max_steps=1001,  # default is 4000 I changed to 2k so it stops training early and export model to HF repo\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_eval_batch_size=8,  #was working with 1 but very slow\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "    save_steps=200,\n",
        "    eval_steps=200,\n",
        "    logging_steps=200,\n",
        "    report_to=[\"tensorboard\"],\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"wer\",\n",
        "    greater_is_better=False,\n",
        "    push_to_hub=True,\n",
        "    hub_token = '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',\n",
        "    #optim=\"adamw_bnb_8bit\",\n",
        ")"
      ],
      "metadata": {
        "id": "-RhXA3HG0UoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsW-WZcL1ZtN"
      },
      "source": [
        "Now, all instances can be passed to Trainer and we are ready to start training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY7vBmFCPFgC"
      },
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    data_collator=data_collator,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=timit_train,\n",
        "    eval_dataset=timit_test,\n",
        "    tokenizer=processor.feature_extractor,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor.save_pretrained(training_args.output_dir)"
      ],
      "metadata": {
        "id": "COaGLAo6qyj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpvZHM1xReIW"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYYAvgkW4P0m"
      },
      "source": [
        "```javascript\n",
        "function ConnectButton(){\n",
        "    console.log(\"Connect pushed\");\n",
        "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click()\n",
        "}\n",
        "setInterval(ConnectButton,60000);\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UEjJqGsQw24"
      },
      "source": [
        "#trainer.train(resume_from_checkpoint=True)\n",
        "trainer.train()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "id": "3O73H-aAwdDZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}