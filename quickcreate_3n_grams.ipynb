{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Boosting Wav2Vec2 with n-grams in ðŸ¤— Transformers",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beinghorizontal/wav2vec2/blob/main/quickcreate_3n_grams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "Wp6XU-5qwI_m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-mE9CiYHXX4G",
        "outputId": "6db92093-e59b-4139-a37c-0a089f3cacf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **part 1. Build an *n-gram* with KenLM** and upload binary to drive\n",
        "\n"
      ],
      "metadata": {
        "id": "OHQXHWZIFN6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, let's see step-by-step how to build an *n-gram*. We will use the popular [KenLM library](https://github.com/kpu/kenlm) to do so. Let's start by installing the Ubuntu library prerequisites:"
      ],
      "metadata": {
        "id": "B4pX7mEXOH_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install build-essential cmake libboost-system-dev libboost-thread-dev libboost-program-options-dev libboost-test-dev libeigen3-dev zlib1g-dev libbz2-dev liblzma-dev"
      ],
      "metadata": {
        "id": "FKMMWfVQp_gP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "before downloading and unpacking the KenLM repo."
      ],
      "metadata": {
        "id": "JzHiJPg6OqvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O - https://kheafield.com/code/kenlm.tar.gz | tar xz"
      ],
      "metadata": {
        "id": "J8mm4ExzqIaZ",
        "outputId": "dcea6ae8-5702-436f-eaf9-c7e6116f62bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-21 18:54:20--  https://kheafield.com/code/kenlm.tar.gz\n",
            "Resolving kheafield.com (kheafield.com)... 35.196.63.85\n",
            "Connecting to kheafield.com (kheafield.com)|35.196.63.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 491888 (480K) [application/x-gzip]\n",
            "Saving to: â€˜STDOUTâ€™\n",
            "\n",
            "-                   100%[===================>] 480.36K   410KB/s    in 1.2s    \n",
            "\n",
            "2022-08-21 18:54:23 (410 KB/s) - written to stdout [491888/491888]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KenLM is written in C++, so we'll make use of `cmake` to build the binaries."
      ],
      "metadata": {
        "id": "TKpjSxiDPKK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir kenlm/build && cd kenlm/build && cmake .. && make -j2\n",
        "!ls kenlm/build/bin"
      ],
      "metadata": {
        "id": "MS4mqMyZqVAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "def make_archive(source, destination):\n",
        "          base = os.path.basename(destination)\n",
        "          name = base.split('.')[0]\n",
        "          format = base.split('.')[1]\n",
        "          archive_from = os.path.dirname(source)\n",
        "          archive_to = os.path.basename(source.strip(os.sep))\n",
        "          shutil.make_archive(name, format, archive_from, archive_to)\n",
        "          shutil.move('%s.%s'%(name,format), destination)\n",
        "\n",
        "make_archive('/content/kenlm', '/content/drive/MyDrive/kenlm.zip')\n",
        "  "
      ],
      "metadata": {
        "id": "VJ_B7WjVyBjq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, as we can see, the executable functions have successfully been built under `kenlm/build/bin/`.\n",
        "\n",
        "KenLM by default computes an *n-gram* with [Kneser-Ney smooting](https://en.wikipedia.org/wiki/Kneser%E2%80%93Ney_smoothing). All text data used to create the *n-gram* is expected to be stored in a text file.\n",
        "We download our dataset and save it as a `.txt` file."
      ],
      "metadata": {
        "id": "N9D7JvVuPTOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try without flag first\n",
        "!kenlm/build/bin/lmplz -o 3 <\"/content/drive/MyDrive/textfile_ngram.txt\" > \"3gram.arpa\"\n",
        "\n",
        "#!kenlm/build/bin/lmplz -o 5 <\"/content/drive/MyDrive/textfile_ngram.txt\" > \"5gram.arpa\" --discount_fallback\n"
      ],
      "metadata": {
        "id": "_MdDNBlZrPOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, we have built a *5-gram* LM! Let's inspect the first couple of lines."
      ],
      "metadata": {
        "id": "1_58ktqcTBYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head -20 3gram.arpa"
      ],
      "metadata": {
        "id": "TRnV8Miusl--",
        "outputId": "5d42c3e3-fc31-4f8c-af82-d84f712b2650",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "head: cannot open '5gram.arpa' for reading: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a small problem that ðŸ¤— Transformers will not be happy about later on.\n",
        "The *5-gram* correctly includes a \"Unknown\" or `<unk>`, as well as a *begin-of-sentence*, `<s>` token, but no *end-of-sentence*, `</s>` token.\n",
        "This sadly has to be corrected currently after the build.\n",
        "\n",
        "We can simply add the *end-of-sentence* token by adding the line `0 </s>  -0.11831701` below the *begin-of-sentence* token and increasing the `ngram 1` count by 1. Because the file has roughly 100 million lines, this command will take *ca.* 2 minutes."
      ],
      "metadata": {
        "id": "l3jfwr2RTKPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"3gram.arpa\", \"r\") as read_file, open(\"3gram_correct.arpa\", \"w\") as write_file:\n",
        "  has_added_eos = False\n",
        "  for line in read_file:\n",
        "    if not has_added_eos and \"ngram 1=\" in line:\n",
        "      count=line.strip().split(\"=\")[-1]\n",
        "      write_file.write(line.replace(f\"{count}\", f\"{int(count)+1}\"))\n",
        "    elif not has_added_eos and \"<s>\" in line:\n",
        "      write_file.write(line)\n",
        "      write_file.write(line.replace(\"<s>\", \"</s>\"))\n",
        "      has_added_eos = True\n",
        "    else:\n",
        "      write_file.write(line)"
      ],
      "metadata": {
        "id": "_7u7dVPkvyRZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now inspect the corrected *5-gram*."
      ],
      "metadata": {
        "id": "u9Y8uC3VW5vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head -20 3gram_correct.arpa"
      ],
      "metadata": {
        "id": "YF1RSm-Pxst5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, this looks better! We're done at this point and all that is left to do is to correctly integrate the `\"ngram\"` with [`pyctcdecode`](https://github.com/kensho-technologies/pyctcdecode) and ðŸ¤— Transformers."
      ],
      "metadata": {
        "id": "m7NfKtyjXCiE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### compress to binary"
      ],
      "metadata": {
        "id": "Qhwcy9aCczQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kenlm/build/bin/build_binary /content/3gram_correct.arpa /content/3gram.bin"
      ],
      "metadata": {
        "id": "RR_yll5ec3Vm",
        "outputId": "1f9923bb-61f5-463b-b576-61b265cfa57a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading /content/3gram_correct.arpa\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Important\n",
        "### Edit unigram.txt and remove unicodes and then save it on drive and close the colab"
      ],
      "metadata": {
        "id": "CLaVV9DM_l3a"
      }
    }
  ]
}